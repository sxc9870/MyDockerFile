1.修改根目录下/etc/hadoop下的hadoop-env.sh 修改里面的java_home
2.修改core-site.xml
  <configuration><property> <name>fs.defaultFS</name> <value>hdfs://172.22.0.2:9000</value> <!--nameNode地址-->
    </property>
     <name>hadoop.tmp.dir</name>    <!--临时文件路径-->
     <value>/home/hadoop/temp</value>
  </property>
</configuration>

3.配置hdfs-site.xml
  <configuration>

<property>
        <name>dfs.replication</name><value>1</value>  <!--设置副本数-->

</property>
</configuration>

4.配置mapred-side.xml

<configuration>
<property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
</property>

</configuration>

5.配置 yarn-side.xml

<configuration>

<!-- Site specific YARN configuration properties -->

<property>
     <name>yarn.resourcemanager.hostname</name>             <!--resourceManager 的地址-->
     <value>localhost</value>
</property>
           <property>
    <name>yarn.nodemanager.aux-services</name><value>mapreduce_shffle</value>

   </property>


</configuration>

6.配置haddophome


配置   export HADOOP_HOME=/home/hadoop-3.1.2

7. bin目录下

8. 安装并开启SSH服务,给秘钥,用于远程访问(yarn-side.xml 貌似要用到这个吧)

 docker-compose down --rmi all &&docker-compose up -d
 docker exec -it hadoop /bin/bash


9.
start-dfs.sh

cd $HADOOP_HOME/bin
./hdfs namenode -format

/usr/sbin/sshd
/usr/sbin/sshd-keygen -A
/usr/sbin/sshd

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys


cd $HADOOP_HOME/sbin/
./start-all.sh
jps
HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root


start-yarn.sh
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root

10. 外部宿主机无法下载文件和上传文件为0KB
https://blog.csdn.net/hzylmf/article/details/47974661

宿主机是没有桌面环境，只能通过实体机在浏览器中访问集群提供的web UI，但现在实体机无法ping通容器地址，也无法访问容器，原因在于，宿主机是实体机的子网，容器是宿主机的子网，而实体机不知道容器所在子网的存在，所以需要在实体机中添加一条从实体机到容器子网的路由。

用管理员模式运行cmd，执行如下命令：


route add -p 172.102.0.0 mask 255.255.255.0 192.168.239.135
三个地址分别为：<目的子网地址> <掩码地址> <网关/宿主机地址>，之后，在实体机中可以正常ping通容器，web控制台也能正常打开了。

可能是实体机上传文件,请求虚拟机地址的时候,跳转到了子网 172.17.XXX的请求.实体机无法访问导致无法上传或者下载问题
route add 以后实体机能直接访问容器以后 可以跳转解决了该问题


11.集群 先用password 设置密码
 scp ~/.ssh/id_rsa.pub  root@hadoop:~/.ssh/id_rsa.pub_hadoop 复制密码的公钥

 scp ~/.ssh/id_rsa.pub  root@hadoop:~/.ssh/id_rsa.pub_from_hadoop2
scp ~/.ssh/id_rsa.pub  root@hadoop2:~/.ssh/id_rsa.pub_from_hadoop2
scp ~/.ssh/id_rsa.pub  root@hadoop3:~/.ssh/id_rsa.pub_from_hadoop2


cat id_rsa.pub_from_hadoop3 >>authorized_keys
cat id_rsa.pub_from_hadoop2 >>authorized_keys
cat id_rsa.pub_from_hadoop >>authorized_keys

 主节点:namenode,recourceNode  修改master的 core-site  hdfs本机
        修改slaves(2.x).works(3.x)

 从节点:datanode,nodemanager

 主节点 formatdata+  ./start-all 会根据works自动启动从节点的datanode